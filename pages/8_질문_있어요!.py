import streamlit as st
from openai import OpenAI


st.set_page_config(
    page_title="ì§ˆë¬¸ ìˆì–´ìš”! | ë‡Œì¡¸ì¤‘ ë°”ë¡œì•Œê¸°",
    page_icon="./static/thumbnail.jpg",
    
)


# ì»¤ìŠ¤í…€ ì‚¬ì´ë“œ ë°”
st.sidebar.title("ë¬´ì—‡ì´ ê¶ê¸ˆí•˜ì„¸ìš”?")
st.sidebar.markdown("## ")
st.sidebar.page_link("app.py", label="ğŸ  í™ˆí˜ì´ì§€")
st.sidebar.page_link("pages/1_ìœ„í—˜ìš”ì¸.py", label="1ï¸âƒ£ ìœ„í—˜ìš”ì¸")
st.sidebar.page_link("pages/2_ì¦ìƒê³¼_ëŒ€ì²˜ë°©ë²•.py", label="2ï¸âƒ£ ì¦ìƒ & ëŒ€ì²˜ë°©ë²•")
st.sidebar.page_link("pages/3_ì¹˜ë£Œë°©ë²•.py", label="3ï¸âƒ£ ì¹˜ë£Œë°©ë²•")
st.sidebar.page_link("pages/4_í‡´ì›_í›„_ìê°€ê´€ë¦¬.py", label="4ï¸âƒ£ í‡´ì› í›„ ìê°€ê´€ë¦¬")
st.sidebar.page_link("pages/5_ìƒí™œìŠµê´€_ê´€ë¦¬.py", label="5ï¸âƒ£ ìƒí™œìŠµê´€ ê´€ë¦¬")
st.sidebar.page_link("pages/6_ì§‘ì—ì„œ_í›ˆë ¨í•˜ëŠ”_ì¬í™œ.py", label="6ï¸âƒ£ ì§‘ì—ì„œ í›ˆë ¨í•˜ëŠ” ì¬í™œ")
st.sidebar.page_link("pages/7_ìì£¼_ë¬»ëŠ”_ì§ˆë¬¸ë“¤.py", label="7ï¸âƒ£ ìì£¼ ë¬»ëŠ” ì§ˆë¬¸")
st.sidebar.page_link("pages/9_ë”_ë§ì€_ì •ë³´.py", label="8ï¸âƒ£ ë” ë§ì€ ì •ë³´")
st.sidebar.page_link("pages/8_ì§ˆë¬¸_ìˆì–´ìš”!.py", label="ğŸ˜ ì œê°€ ë‹µí•´ë“œë¦´ê²Œìš”!")
st.sidebar.page_link("pages/10_ì»¤ë®¤ë‹ˆí‹°.py", label="ğŸŒ ì»¤ë®¤ë‹ˆí‹°")


st.title("ì œê°€ ë‹µí•´ë“œë¦´ê²Œìš”!")
st.markdown("<div style='height: 30px;'></div>", unsafe_allow_html=True)  # ê³µê°„ ì¶”ê°€
st.markdown("""
            ê°„ë‹¨í•œ ì§ˆë¬¸ì€ ì±—ë´‡ì´ ë„ì™€ë“œë¦´ ìˆ˜ ìˆì–´ìš”! ğŸ’ªğŸ˜  
            ì±—ë´‡ìœ¼ë¡œ í•´ê²°í•  ìˆ˜ ì—†ëŠ” ì§ˆë¬¸ì€ 'ì»¤ë®¤ë‹ˆí‹°'ì— ë‚¨ê²¨ì£¼ì„¸ìš”!""")

st.divider()  # ğŸ‘ˆ Draws a horizontal rule

# Set OpenAI API key from Streamlit secrets
client = OpenAI(api_key=st.secrets["openai"]["OPENAI_API_KEY"])

# Set a default model
if "openai_model" not in st.session_state:
    st.session_state["openai_model"] = "gpt-3.5-turbo"

# Initialize chat history
if "messages" not in st.session_state:
    st.session_state.messages = []

# Display chat messages from history on app rerun
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Accept user input
if prompt := st.chat_input("What is up?"):
    # Add user message to chat history
    st.session_state.messages.append({"role": "user", "content": prompt})
    # Display user message in chat message container
    with st.chat_message("user"):
        st.markdown(prompt)

    # Display assistant response in chat message container
    with st.chat_message("assistant"):
        stream = client.chat.completions.create(
            model=st.session_state["openai_model"],
            messages=[
                {"role": m["role"], "content": m["content"]}
                for m in st.session_state.messages
            ],
            stream=True,
        )
        response = st.write_stream(stream)
    st.session_state.messages.append({"role": "assistant", "content": response})

